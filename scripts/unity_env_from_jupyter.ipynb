{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a55a3e7a-9087-4dcb-84dd-540d08b9c4d0",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mlagents_envs.environment import UnityEnvironment\n",
    "from mlagents_envs.side_channel.engine_configuration_channel import EngineConfigurationChannel\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Normal\n",
    "import torch.nn.functional as F\n",
    "import torch.onnx\n",
    "#import torchvision\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from mlagents_envs.base_env import ActionTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e39f0aa3-1459-4080-841c-274631b3edfe",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "writer = SummaryWriter()\n",
    "\n",
    "lr = 1e-5\n",
    "clip_param = 0.2\n",
    "lambd_param = 0.95\n",
    "gamma_param = 0.99\n",
    "num_epochs_list = [100]\n",
    "num_episodes = 512\n",
    "ppo_batch_size = 512\n",
    "mini_batch_size = 64\n",
    "ppo_epoch = 4 #conventionally, 4\n",
    "entropy_coef_param = 0.01\n",
    "\n",
    "input_channel = 23\n",
    "action_size = 6\n",
    "\n",
    "\n",
    "print(use_cuda)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c956b96-1178-4901-b631-462c253d49cc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Creating model(Actor-critic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcb48804-ac9f-49b8-9639-71247f38e175",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_shape_hook(module, input, output):\n",
    "    print(f\"{module.__class__.__name__}: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d2bfdc9-18d7-44f5-8c45-bbb1ab5cc2a6",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#need to change the input size of linear layer\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, input_channel, action_dim):\n",
    "        super(Actor, self).__init__()\n",
    "        self.convs = nn.Sequential(\n",
    "            nn.Conv2d(input_channel, 96, 4, 4),\n",
    "            nn.Conv2d(96, 96, 7),\n",
    "            nn.Conv2d(96, 384, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384,96,1),\n",
    "            nn.Conv2d(96, 192, 7),\n",
    "            nn.Conv2d(192, 768,1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(768, 192, 1),\n",
    "\n",
    "            # add more Conv layers according to your input size of the image (more than 110 x 110)\n",
    "            \n",
    "            # nn.Conv2d(192, 384, 7),\n",
    "            # nn.Conv2d(384, 1536, 1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Conv2d(1536, 384, 1),\n",
    "            # nn.Conv2d(384, 768,7),\n",
    "            # nn.Conv2d(768, 3072,1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Conv2d(3072, 768, 1),\n",
    "            # nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # for conv_layer in self.convs:\n",
    "        #     conv_layer.register_forward_hook(print_shape_hook)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.linear = nn.Linear(43200, action_dim)\n",
    "        self.log_std = nn.Parameter(torch.ones((1,action_dim)))\n",
    "\n",
    "    def forward(self, observation):\n",
    "        x = self.convs(observation)\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear(x)\n",
    "\n",
    "        std = self.log_std.exp().expand_as(logits)\n",
    "        dist = Normal(logits, std)\n",
    "        actions = dist.sample()\n",
    "\n",
    "        actions_1_to_4 = actions[..., :4]\n",
    "        actions_5_and_6 = actions[..., 4:]\n",
    "\n",
    "        scaled_actions_1_to_4 = torch.tanh(actions_1_to_4)\n",
    "        scaled_actions_5_and_6 = torch.sigmoid(actions_5_and_6)\n",
    "\n",
    "        scaled_actions = torch.cat([scaled_actions_1_to_4, scaled_actions_5_and_6], dim=-1)\n",
    "        \n",
    "        log_probs = dist.log_prob(actions)\n",
    "        entropy = dist.entropy()\n",
    "        \n",
    "        return scaled_actions, log_probs, entropy\n",
    "\n",
    "    def reInstantiate_fc_layer_input_size(self, input_shape, output_shape=6):\n",
    "        x = torch.randn(input_shape).to(device)\n",
    "        with torch.no_grad():\n",
    "            output = self.convs(x)\n",
    "\n",
    "        flatten_output = output.view(1, -1).size(1)\n",
    "        print(f\"new fc layer input size: {flatten_output}\")\n",
    "\n",
    "        self.linear = nn.Linear(flatten_output, output_shape).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4f5c67a-75b0-4e10-b196-0ca1f86b639d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self, input_channel):\n",
    "        super(Critic, self).__init__()\n",
    "        self.convs = nn.Sequential(\n",
    "            nn.Conv2d(input_channel, 96, 4, 4),\n",
    "            nn.Conv2d(96, 96, 7),\n",
    "            nn.Conv2d(96, 384, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384,96,1),\n",
    "            nn.Conv2d(96, 192, 7),\n",
    "            nn.Conv2d(192, 768,1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(768, 192, 1),\n",
    "\n",
    "            # add more layers if input size of image is bigger than default(110 x 110)\n",
    "            \n",
    "            # nn.Conv2d(192, 384, 7),\n",
    "            # nn.Conv2d(384, 1536, 1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Conv2d(1536, 384, 1),\n",
    "            # nn.Conv2d(384, 768,7),\n",
    "            # nn.Conv2d(768, 3072,1),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Conv2d(3072, 768, 1),\n",
    "            # nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # for layer in self.convs:\n",
    "        #     layer.register_forward_hook(print_shape_hook)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear = nn.Linear(43200, 1)\n",
    "\n",
    "    def forward(self, observation):\n",
    "        x = self.convs(observation)\n",
    "        x = self.flatten(x)\n",
    "        value = self.linear(x)\n",
    "\n",
    "        return value\n",
    "\n",
    "    def reInstantiate_fc_layer_input_size(self, input_shape):\n",
    "        x = torch.randn(input_shape).to(device)\n",
    "        with torch.no_grad():\n",
    "            output = self.convs(x)\n",
    "\n",
    "        flatten_output = output.view(1, -1).size(1)\n",
    "        print(f\"new fc layer input size: {flatten_output}\")\n",
    "\n",
    "        self.linear = nn.Linear(flatten_output, output_shape).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862d045e-cc38-46c5-b6ff-3e76dd88b1cb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Initialize PPO and critic update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecc910f0-4e63-47f7-94b1-707440082cc9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#calculate ppo loss for one agent\n",
    "def calc_ppo_loss(ppo_epoch, batch_size, num_agents, states_agent1, states_agent2, log_probs_agent1, log_probs_agent2, entropy_agent1, entropy_agent2, advantages_agent1, advantages_agent2, sigma_param):\n",
    "\n",
    "    assert len(states_agent1) == len(log_probs_agent1) == len(advantages_agent1) == len(entropy_agent1) == len(states_agent2) == len(log_probs_agent2) == len(advantages_agent2) == len(entropy_agent2) \n",
    "    def ppo_iter(mini_batch_size, \n",
    "                 batch_size, \n",
    "                 states_agent1, \n",
    "                 log_probs_agent1, \n",
    "                 entropy_agent1, \n",
    "                 advantages_agent1, \n",
    "                 states_agent2, \n",
    "                 log_probs_agent2, \n",
    "                 entropy_agent2, \n",
    "                 advantages_agent2\n",
    "                ):\n",
    "        for _ in range(batch_size // (mini_batch_size)):\n",
    "            # Generate random indices for sampling\n",
    "            batch_ids = np.random.randint(0, batch_size, mini_batch_size)\n",
    "            \n",
    "            # Yield the mini-batches of states and log probabilities for both agents\n",
    "            yield (\n",
    "                states_agent1[batch_ids, :, :, :],\n",
    "                states_agent2[batch_ids, :, :, :],\n",
    "                log_probs_agent1[batch_ids, :],\n",
    "                log_probs_agent2[batch_ids, :],\n",
    "                entropy_agent1[batch_ids, :],\n",
    "                entropy_agent2[batch_ids, :],\n",
    "                advantages_agent1[batch_ids],\n",
    "                advantages_agent2[batch_ids]\n",
    "            )\n",
    "\n",
    "    for _ in range(ppo_epoch):\n",
    "        for (\n",
    "                state_agent1, state_agent2,\n",
    "                log_probs_old_agent1, log_probs_old_agent2,\n",
    "                entropys_old_agent1, entropys_old_agent2,\n",
    "                advantage_agent1, advantage_agent2\n",
    "            ) in ppo_iter(\n",
    "                mini_batch_size, \n",
    "                batch_size,  \n",
    "                states_agent1,  \n",
    "                log_probs_agent1,  \n",
    "                entropy_agent1, \n",
    "                advantages_agent1,\n",
    "                states_agent2,\n",
    "                log_probs_agent2,\n",
    "                entropy_agent2,\n",
    "                advantages_agent2\n",
    "            ):\n",
    "            \n",
    "            \n",
    "            _ , log_probs_new_agent1, entropy_new_agent1 = agent_model(state_agent1)\n",
    "            _ , log_probs_new_agent2, entropy_new_agent2 = agent_model(state_agent2)\n",
    "            \n",
    "            rt_agent1 = (log_probs_new_agent1 - log_probs_old_agent1).exp()\n",
    "            rt_agent2 = (log_probs_new_agent2 - log_probs_old_agent2).exp()\n",
    "            \n",
    "            clip_agent1 = torch.clamp(rt_agent1, 1 - clip_param, 1 + clip_param)\n",
    "            clip_agent2 = torch.clamp(rt_agent2, 1 - clip_param, 1 + clip_param)\n",
    "            \n",
    "            surr1_agent1 = rt_agent1 * advantage_agent1.unsqueeze(1)\n",
    "            surr2_agent1 = clip_agent1 * advantage_agent1.unsqueeze(1)\n",
    "\n",
    "            surr1_agent2 = rt_agent2 * advantage_agent2.unsqueeze(1)\n",
    "            surr2_agent2 = clip_agent2 * advantage_agent2.unsqueeze(1)\n",
    "            \n",
    "            \n",
    "            agent1_loss = - torch.min(surr1_agent1, surr2_agent1).mean()\n",
    "            entropy_aggre_agent1 = - entropy_new_agent1.mean()\n",
    "\n",
    "            agent2_loss = - torch.min(surr1_agent2, surr2_agent2).mean()\n",
    "            entropy_aggre_agent2 = - entropy_new_agent2.mean()\n",
    "            \n",
    "            \n",
    "            loss = (agent1_loss + agent2_loss + sigma_param * (entropy_aggre_agent1 + entropy_aggre_agent2)) / num_agents\n",
    "            \n",
    "            agent_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            agent_optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bce1172-64b6-4a33-9174-faa5c6762638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mappo_update(ppo_epoch, batch_size, agents_name, states_all, log_probs_all, entropy_all, advantages_all, sigma_param):\n",
    "    loss = 0\n",
    "    num_agents = len(agents_name)\n",
    "    agent1, agent2 = agents_name\n",
    "    calc_ppo_loss(\n",
    "        ppo_epoch, \n",
    "        batch_size, \n",
    "        num_agents, \n",
    "        states_all[agent1], \n",
    "        states_all[agent2], \n",
    "        log_probs_all[agent1], \n",
    "        log_probs_all[agent2], \n",
    "        entropy_all[agent1], \n",
    "        entropy_all[agent2], \n",
    "        advantages_all[agent1], \n",
    "        advantages_all[agent2], \n",
    "        sigma_param\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39f63452-16b3-477f-a878-1f21e02288b1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_critic_loss(critic_update_epoch, batch_size, mini_batch_size, num_agents, states_agent1, states_agent2, values_agent1, values_agent2, returns_agent1, returns_agent2):\n",
    "    def critic_loss_iter(batch_size, \n",
    "                         mini_batch_size, \n",
    "                         states_agent1, \n",
    "                         states_agent2,\n",
    "                         values_agent1,\n",
    "                         values_agent2,\n",
    "                         returns_agent1,\n",
    "                         returns_agent2,\n",
    "                        ):\n",
    "        for _ in range(batch_size // (mini_batch_size)):\n",
    "            batch_ids = np.random.randint(0, batch_size, mini_batch_size)\n",
    "            yield (\n",
    "                states_agent1[batch_ids, :, :, :],\n",
    "                states_agent2[batch_ids, :, :, :],\n",
    "                values_agent1[batch_ids],\n",
    "                values_agent2[batch_ids],\n",
    "                returns_agent1[batch_ids, :],\n",
    "                returns_agent2[batch_ids, :]\n",
    "                \n",
    "            )\n",
    "\n",
    "    for _ in range(critic_update_epoch):\n",
    "        for (\n",
    "            state_agent1, \n",
    "            state_agent2, \n",
    "            values_old_agent1, \n",
    "            values_old_agent2, \n",
    "            return_agent1, \n",
    "            return_agent2) in critic_loss_iter(\n",
    "            batch_size, \n",
    "            mini_batch_size, \n",
    "            states_agent1,\n",
    "            states_agent2,\n",
    "            values_agent1,\n",
    "            values_agent2,\n",
    "            returns_agent1,\n",
    "            returns_agent2\n",
    "        ):\n",
    "            value_new_agent1 = critic_model(state_agent1)\n",
    "            value_new_agent2 = critic_model(state_agent2)\n",
    "\n",
    "            surr1_agent1 = (value_new_agent1 - return_agent1).pow(2).mean()\n",
    "            surr2_agent1 = (torch.clamp(value_new_agent1, values_old_agent1 - clip_param, values_old_agent1 + clip_param) - return_agent1).pow(2).mean()\n",
    "\n",
    "            surr1_agent2 = (value_new_agent2 - return_agent2).pow(2).mean()\n",
    "            surr2_agent2 = (torch.clamp(value_new_agent2, values_old_agent2 - clip_param, values_old_agent2 + clip_param) - return_agent2).pow(2).mean()\n",
    "\n",
    "            critic_loss_agent1 = max(surr1_agent1, surr2_agent1)\n",
    "\n",
    "            critic_loss_agent2 = max(surr1_agent2, surr2_agent2)\n",
    "            loss = (critic_loss_agent1 + critic_loss_agent2) / num_agents\n",
    "            \n",
    "            critic_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            critic_optimizer.step()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47a714fe-a4f0-44e0-97d1-4583ec449b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def critic_update(critic_update_epoch, batch_size, mini_batch_size, agents_name, states_all, values_all, returns_all):\n",
    "    num_agents = len(agents_name)\n",
    "    agent1, agent2 = agents_name\n",
    "    calc_critic_loss(critic_update_epoch, \n",
    "                     batch_size, \n",
    "                     mini_batch_size, \n",
    "                     num_agents, \n",
    "                     states_all[agent1], \n",
    "                     states_all[agent2],\n",
    "                     values_all[agent1],\n",
    "                     values_all[agent2],\n",
    "                     returns_all[agent1], \n",
    "                     returns_all[agent2]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a74bea-d500-4e86-88aa-e099a1118c42",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# GAE for estimating Advantage function\n",
    "\n",
    "Here, we used GAE to estimate reward-to-go by using equation Q = A(estimated) + V "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11e83e8b-1032-40d0-bf56-d9961820999c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#this method is for lambd = 1 in TD(lambd) algorithm\n",
    "def compute_GAE(next_value, values, rewards, gamma, lambd):\n",
    "    gae = 0\n",
    "    returns = []\n",
    "    values = values if len(next_value) == 0 else values + [next_value]\n",
    "    if len(values) == len(rewards) + 1:\n",
    "        for step in reversed(range(len(rewards))):\n",
    "            delta = rewards[step] + (gamma * values[step + 1]) - values[step]\n",
    "            if step == len(rewards) - 1:\n",
    "                gae = 0\n",
    "            else:\n",
    "                gae = delta + gamma * lambd * gae\n",
    "\n",
    "            returns.append(gae + values[step])\n",
    "    else:\n",
    "        for step in reversed(range(1, len(values))):\n",
    "            delta = rewards[step - 1] + (gamma * values[step]) - values[step - 1]\n",
    "            if step == len(values) - 1:\n",
    "                gae = 0\n",
    "            else:\n",
    "                gae = delta + gamma * lambd * gae\n",
    "    \n",
    "            returns.append(gae + values[step])\n",
    "            \n",
    "    returns.reverse()\n",
    "    return returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4039499a-73b7-4f30-81ae-a53def899b76",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_GAE_dict(next_values, values_all, rewards_all, gamma, lambd):\n",
    "    agents_name = [\"agent1\", \"agent2\"]\n",
    "    returns_all = {\"agent1\": [], \"agent2\": []}\n",
    "    for index, agent_name in enumerate(agents_name):\n",
    "        returns_all[agent_name] = compute_GAE(next_values[index], values_all[agent_name], rewards_all[agent_name], gamma, lambd)\n",
    "\n",
    "    return returns_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bee6bf1-4a82-47b2-94b5-9166f9ea1dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Advantage_dict(values_all, returns_all):\n",
    "    advantages_all = {\"agent1\": [], \"agent2\": []}\n",
    "    agents_name = [\"agent1\", \"agent2\"]\n",
    "\n",
    "    for agent_name in agents_name:\n",
    "        for i in range(len(returns_all[agent_name])):\n",
    "            advantages_all[agent_name].append(returns_all[agent_name][i] - values_all[agent_name][i])\n",
    "\n",
    "    return advantages_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "400400e8-0831-45f6-bb68-a864d597b718",
   "metadata": {},
   "outputs": [],
   "source": [
    "values_all = {\"agent1\": torch.Tensor([1,1,1,1]), \"agent2\": [1,1,1,3]}\n",
    "returns_all = {\"agent1\": torch.Tensor([1,3,5,1]), \"agent2\": np.array([1,4,5,6])}\n",
    "\n",
    "advantages_all_dummy = compute_Advantage_dict(values_all, returns_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43b0039e-8598-40ef-95e3-a3d811045987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agent1': [tensor(0.), tensor(2.), tensor(4.), tensor(0.)],\n",
       " 'agent2': [0, 3, 4, 3]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advantages_all_dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b52652-075d-4663-b00a-58b86608bd44",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Config and constant setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91e6b2e6-951f-452f-bf31-cad021960412",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "_actor_visual_obs_from_env = [\n",
    "        #LAYER ORDER\n",
    "        \"CameraSensor\",\n",
    "        \"AgentSensor\",\n",
    "        \"TableSensor\",\n",
    "        \"OnionDispSensor\",\n",
    "        \"DishDispSensor\",\n",
    "        \"ServeDispSensor\",\n",
    "        \"OvenDispSensor\",\n",
    "        \"OnionSensor\",\n",
    "        \"DishSensor\",\n",
    "        \"SoupSensor\",\n",
    "        \"CookingTimerSensor\",\n",
    "        \"IsCookedSensor\"\n",
    "    ]\n",
    "\n",
    "agent_movement_directions = [\"LEFT\", \"RIGHT\", \"UP\", \"DOWN\"]\n",
    "\n",
    "\n",
    "sorted_obs_order = [   \n",
    "        \"CameraSensor_1\",\n",
    "        \"CameraSensor_2\",\n",
    "        \"CameraSensor_3\",\n",
    "        \"AgentSensor\",\n",
    "        \"AgentSensor_UP\",\n",
    "        \"AgentSensor_DOWN\",\n",
    "        \"AgentSensor_RIGHT\",\n",
    "        \"AgentSensor_LEFT\",\n",
    "        \"OtherAgentSensor\",\n",
    "        \"OtherAgentSensor_UP\",\n",
    "        \"OtherAgentSensor_DOWN\",\n",
    "        \"OtherAgentSensor_RIGHT\",\n",
    "        \"OtherAgentSensor_LEFT\",\n",
    "        \"TableSensor\",\n",
    "        \"OnionDispSensor\",\n",
    "        \"DishDispSensor\",\n",
    "        \"ServeDispSensor\",\n",
    "        \"OvenDispSensor\",\n",
    "        \"OnionSensor\",\n",
    "        \"DishSensor\",\n",
    "        \"SoupSensor\",\n",
    "        \"CookingTimerSensor\",\n",
    "        \"IsCookedSensor\"\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62ac2a9f-a7f1-4eb6-87d2-48dff8b2eb18",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def setupUnityEnv(url:str = None, time_scale:float = 20.0):\n",
    "    # Optional: Set up engine configurations like rendering and time scale\n",
    "    engine_channel = EngineConfigurationChannel()\n",
    "    engine_channel.set_configuration_parameters(time_scale=time_scale) # Faster simulation\n",
    "\n",
    "    # Initialize the Unity environment with the executable\n",
    "    env = UnityEnvironment(file_name=url, side_channels=[engine_channel])\n",
    "    env.reset()  # Start a new episode\n",
    "\n",
    "    return env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c397d2a-daf2-4bd1-95bf-b4aa0055ef12",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def addDirectionLayer(layer_dict,direction_obs):\n",
    "    x_axis, y_axis = direction_obs.squeeze(0)\n",
    "\n",
    "    for direction in agent_movement_directions:\n",
    "        layer_initailize = np.zeros_like(layer_dict[\"AgentSensor\"])\n",
    "        layer_dict[f\"AgentSensor_{direction}\"] = layer_initailize\n",
    "\n",
    "    def chooseDirectionLayer(axis, axis_name):\n",
    "        direct = {\n",
    "            \"x\": [\"LEFT\", \"RIGHT\"],\n",
    "            \"y\":[\"DOWN\", \"UP\"]\n",
    "        }\n",
    "        direction = str()\n",
    "        if axis < 0:\n",
    "            direction = direct[axis_name][0]\n",
    "        elif axis > 0:\n",
    "            direction = direct[axis_name][1]\n",
    "        else:\n",
    "            direction = None\n",
    "\n",
    "        return direction\n",
    "    \n",
    "    agent_directions = [chooseDirectionLayer(x_axis, \"x\"), chooseDirectionLayer(y_axis,\"y\")]\n",
    "    \n",
    "    for agent_direction in agent_directions:\n",
    "        if agent_direction is None:\n",
    "            continue\n",
    "\n",
    "        layer_visual_vector = layer_dict[\"AgentSensor\"]\n",
    "        layer_dict[f\"AgentSensor_{agent_direction}\"] = layer_visual_vector\n",
    "    \n",
    "    return layer_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdaea075-5f6e-44b2-8ea2-0c64d1485785",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def addOtherAgentLayers(layer_dict,agent_name,other_agent_name):\n",
    "    other_agent_layer_names = {\n",
    "        \"OtherAgentSensor\": \"AgentSensor\",\n",
    "        \"OtherAgentSensor_UP\": \"AgentSensor_UP\",\n",
    "        \"OtherAgentSensor_DOWN\": \"AgentSensor_DOWN\",\n",
    "        \"OtherAgentSensor_RIGHT\": \"AgentSensor_RIGHT\",\n",
    "        \"OtherAgentSensor_LEFT\":\"AgentSensor_LEFT\"\n",
    "    }\n",
    "\n",
    "    for key, value in other_agent_layer_names.items():\n",
    "        layer_dict[agent_name][key] = layer_dict[other_agent_name][value]\n",
    "\n",
    "    return layer_dict[agent_name]\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84596627-703f-4ae9-8ed0-f8235fbcc907",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# instantiate Actor and Critic model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "505c08ea-f486-4e6a-a491-7cc0b609a984",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor(\n",
      "  (convs): Sequential(\n",
      "    (0): Conv2d(23, 96, kernel_size=(4, 4), stride=(4, 4))\n",
      "    (1): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (2): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (5): Conv2d(96, 192, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (6): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear): Linear(in_features=43200, out_features=6, bias=True)\n",
      ")\n",
      "Critic(\n",
      "  (convs): Sequential(\n",
      "    (0): Conv2d(23, 96, kernel_size=(4, 4), stride=(4, 4))\n",
      "    (1): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (2): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (5): Conv2d(96, 192, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (6): Conv2d(192, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear): Linear(in_features=43200, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "agent_model = Actor(23, 6).to(device)\n",
    "critic_model = Critic(23).to(device)\n",
    "\n",
    "agent_optimizer = optim.Adam(agent_model.parameters(), lr=lr)\n",
    "critic_optimizer = optim.Adam(critic_model.parameters(), lr=lr)\n",
    "\n",
    "for param in agent_model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "print(agent_model)\n",
    "print(critic_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7fbb3e04-e910-4c61-9327-fd01e81d67e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_params(model):\n",
    "    for layer in model.modules():\n",
    "        if hasattr(layer, \"reset_parameters\"):\n",
    "            layer.reset_parameters()\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e950a87e-d359-44b3-b59a-098b59a75360",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_all_agent_trajectory(trajectory: dict(), feature_name):\n",
    "    print(f\"{feature_name}: \\n\")\n",
    "    print(\"agent1\")\n",
    "    print(trajectory[\"agent1\"].shape if type(trajectory[\"agent1\"]) == np.ndarray else type(trajectory[\"agent1\"]))\n",
    "    print(\"agent2\")\n",
    "    print(trajectory[\"agent2\"].shape if type(trajectory[\"agent2\"]) == np.ndarray else type(trajectory[\"agent2\"]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4ed9199-8ee0-420e-b56f-254ace82f183",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transfer_to_numpy(dictionary: dict):\n",
    "    if type(dictionary[\"agent1\"]) is torch.Tensor or type(dictionary[\"agent2\"]) is torch.Tensor:\n",
    "        numpy_array1, numpy_array2 = dictionary[\"agent1\"].numpy(force=True), dictionary[\"agent2\"].numpy(force=True)\n",
    "    else:\n",
    "        numpy_array1, numpy_array2 = np.array(dictionary[\"agent1\"], dtype=np.float32), np.array(dictionary[\"agent2\"], dtype=np.float32)\n",
    "        \n",
    "    numpy_dictionary = {\"agent1\": numpy_array1, \"agent2\": numpy_array2}\n",
    "    return numpy_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6709eed5-f613-4535-b618-06a86bf2970e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "decision_steps_dummy = [1,1,1]\n",
    "terminal_steps_dummy = [1,]\n",
    "dones_dummy = []\n",
    "\n",
    "dones_dummy.append(0 if len(terminal_steps_dummy) == 0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca3acbef-42e1-40fd-96a2-f595a0bbd5a5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def concat_tensor_dict(trajectory_dict):\n",
    "    tensor_dict = dict()\n",
    "    for key, value in trajectory_dict.items():\n",
    "        tensor_dict[key] = torch.cat(value)\n",
    "    return tensor_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e79cfb9b-3efb-497a-878a-292c31111d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_list_into_tensor_dict(trajectory_dict):\n",
    "    tensor_dict = dict()\n",
    "    for key, value in trajectory_dict.items():\n",
    "        tensor_dict[key] = torch.stack(value)\n",
    "    return tensor_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3c7205b-bf08-482e-a13e-d4f7ca365608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_total_reward(rewards_all):\n",
    "    total_rewards = []\n",
    "    for key, value in rewards_all.items():\n",
    "        reward_plus = 0\n",
    "        for index, reward_agent in enumerate(value):\n",
    "            if reward_agent > 0:\n",
    "                # print(f'index: {index}, reward_agent1: {reward_agent}')\n",
    "                reward_plus = reward_plus + reward_agent\n",
    "        total_rewards.append(reward_plus)\n",
    "\n",
    "    return total_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8931bd64-69d0-4ae5-aa9f-915b584fb83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_dummy = {\"agent1\": [torch.tensor([[1.0], [2.5]]), torch.tensor([[3.0], [4.0]])]}\n",
    "\n",
    "tensor_dummy = concat_tensor_dict(dict_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6769d17-b161-4ba0-aef4-8953c5e08787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agent1': tensor([[1.0000],\n",
       "         [2.5000],\n",
       "         [3.0000],\n",
       "         [4.0000]])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5eea1d80-eacf-4f3e-8ae1-5c80f156e871",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rewards_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d66e7280-c047-4ce6-9cd2-a9408411b98f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Set up the path to the Unity executable\n",
    "    env_path = \"../CAIPlatform/Build/v2-2/platform_v2_2_dualAgent.x86_64\"  # Replace with your actual build path\n",
    "\n",
    "    env = setupUnityEnv(env_path)\n",
    "    env.reset()\n",
    "    \n",
    "    # Set up to interact with the environment\n",
    "\n",
    "    agent_names = list(env.behavior_specs)\n",
    "    agent1, agent2 = agent_names\n",
    "    print(f\"Agents: {list(env.behavior_specs)}\")\n",
    "    print(type(env.behavior_specs))\n",
    "    for num_epochs in num_epochs_list:\n",
    "        \n",
    "        agent_model = Actor(23, 6).to(device)\n",
    "        critic_model = Critic(23).to(device)\n",
    "        \n",
    "        agent_optimizer = optim.Adam(agent_model.parameters(), lr=lr)\n",
    "        critic_optimizer = optim.Adam(critic_model.parameters(), lr=lr)\n",
    "        \n",
    "        for param in agent_model.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        total_rewards_epochs = []\n",
    "        \n",
    "        for num_epoch in range(num_epochs):\n",
    "            states_agent1 = []  # Observations for Agent 1\n",
    "            states_agent2 = []  # Observations for Agent 2\n",
    "            \n",
    "            states_all = {\"agent1\": [], \"agent2\": []}\n",
    "            actions_all = {\"agent1\": [], \"agent2\": []}\n",
    "            log_probs_all = {\"agent1\": [],\"agent2\": [] }\n",
    "            entropy_all = {\"agent1\": [], \"agent2\": []}\n",
    "            values_all = {\"agent1\": [], \"agent2\": []}\n",
    "            rewards_all = {\"agent1\": [], \"agent2\": []}\n",
    "            \n",
    "            returns_all = dict()  # Returns calculated for the trajectory\n",
    "            advantages_all = dict()  # Advantage estimates for PPO\n",
    "            \n",
    "            dones = []  # Whether the episode ended at this step\n",
    "            terminal_info = {\"terminal_steps\": list(), \"observation_specs\": None, \"agent_name\": str(), \"other_agent\": str()}\n",
    "            terminal_steps = None\n",
    "            \n",
    "            env.reset()\n",
    "            \n",
    "            for num_episode in range(num_episodes):\n",
    "                \n",
    "                agents_obs = dict()\n",
    "                agents_obs_in_array = []\n",
    "                for index, agent_name in enumerate(agent_names):\n",
    "                    spec = env.behavior_specs[agent_name]\n",
    "            \n",
    "                    decision_steps, terminal_steps = env.get_steps(agent_name)\n",
    "                    \n",
    "                    dones.append(0 if len(terminal_steps) == 0 else 1)\n",
    "                    if dones[-1] == 1:\n",
    "                        terminal_info[\"terminal_steps\"] = terminal_steps\n",
    "                        terminal_info[\"observation_specs\"] = spec.observation_specs\n",
    "                        terminal_info[\"agent_name\"] = agent_name\n",
    "                        terminal_info[\"other_agent\"] = agent1 if agent1 != agent_name else agent2\n",
    "                        break\n",
    "                    \n",
    "                    for agent_id in decision_steps.agent_id_to_index:\n",
    "                        reward = decision_steps[agent_id].reward\n",
    "                        # print(f\"Agent {agent_id} reward: {reward}\")\n",
    "                        rewards_all[f\"agent{agent_id + 1}\"].append(reward)\n",
    "                        \n",
    "                    \n",
    "                    # visual_obs, direction = sort_obs_from_env(spec.observation_specs)\n",
    "                    \n",
    "                    temp_input = dict()\n",
    "                        \n",
    "                    for index, obs_step in enumerate(spec.observation_specs):\n",
    "                        \n",
    "                        if len(obs_step.shape) == 3:\n",
    "                            if obs_step.name == \"CameraSensor\":\n",
    "                                for idx in range(len(decision_steps.obs[index].squeeze(0) )):\n",
    "                                    temp_input[f\"{obs_step.name}_{idx + 1}\"] = decision_steps.obs[index].squeeze(0)[idx]\n",
    "                            else:\n",
    "                                temp_input[obs_step.name] = decision_steps.obs[index].squeeze(0).squeeze(0)\n",
    "            \n",
    "                            \n",
    "                        else:\n",
    "                            temp_input = addDirectionLayer(temp_input, decision_steps.obs[index])\n",
    "                \n",
    "                    agents_obs[agent_name] = temp_input\n",
    "                \n",
    "                if dones[-1] == 1:\n",
    "                    break\n",
    "                    \n",
    "                agents_obs[agent1]= addOtherAgentLayers(agents_obs, agent1, agent2)\n",
    "                agents_obs[agent2] = addOtherAgentLayers(agents_obs, agent2, agent1)\n",
    "            \n",
    "                #input dictionary -> sorted array (as sorted_obs_order)\n",
    "                for agent_name in agent_names:\n",
    "                    agent_obs_in_array = []\n",
    "                    for sorted_layer in sorted_obs_order:\n",
    "                        agent_obs_in_array.append(agents_obs[agent_name][sorted_layer])\n",
    "                    agents_obs_in_array.append(agent_obs_in_array)\n",
    "                \n",
    "                #array -> numpy array \n",
    "                agents_obs_in_array = np.array(agents_obs_in_array, dtype=np.float32)\n",
    "                #obs -> state (save it for later)\n",
    "                # sprint(agents_obs_in_array.shape)\n",
    "                agents_obs_in_array = torch.from_numpy(agents_obs_in_array).to(device)\n",
    "                states_agent1.append(agents_obs_in_array[0])\n",
    "                states_agent2.append(agents_obs_in_array[1])\n",
    "                \n",
    "                actions, log_probs, entropy = agent_model(agents_obs_in_array)\n",
    "                values = critic_model(agents_obs_in_array)\n",
    "                \n",
    "                for index, agent_name in enumerate(agent_names):\n",
    "                    actions_all[f\"agent{index + 1}\"].append(actions[index].detach().cpu().numpy())\n",
    "                    log_probs_all[f\"agent{index + 1}\"].append(log_probs[index].detach())\n",
    "                    entropy_all[f\"agent{index + 1}\"].append(entropy[index].detach())\n",
    "                    values_all[f\"agent{index + 1}\"].append(values[index].detach())\n",
    "                    \n",
    "                    agent_action_tensor = actions[index].unsqueeze(0)\n",
    "                    action_tuple = ActionTuple(continuous=agent_action_tensor.numpy(force=True))\n",
    "                    env.set_actions(agent_name, action_tuple)\n",
    "                    \n",
    "                env.step()\n",
    "                \n",
    "    \n",
    "            #compute adavantage function with GAE here (this is why i cannot detach it at the same place with the others)\n",
    "    \n",
    "            # print(f'terminal_info:[terminal_steps: {terminal_info[\"terminal_steps\"] is not None}, \\n observation_specs:{terminal_info[\"observation_specs\"] is not None}, \\n agent_name: {terminal_info[\"agent_name\"]} \\n other_agent: {terminal_info[\"other_agent\"]}')\n",
    "            \n",
    "            if len(terminal_info[\"terminal_steps\"]) > 0:\n",
    "                agents_obs = dict()\n",
    "                agents_obs_in_array = []\n",
    "                temp_input = dict()\n",
    "                        \n",
    "                for index, obs_step in enumerate(terminal_info[\"observation_specs\"]):\n",
    "                    \n",
    "                    print(f'obs_name: {obs_step.name}, shape: {terminal_info[\"terminal_steps\"].obs[index].shape}, obs_step.shape: {obs_step.shape}')\n",
    "                    if len(obs_step.shape) == 3:\n",
    "                        if obs_step.name == \"CameraSensor\":\n",
    "                            for idx in range(len(terminal_info[\"terminal_steps\"].obs[index].squeeze(0) )):\n",
    "                                temp_input[f\"{obs_step.name}_{idx + 1}\"] = terminal_info[\"terminal_steps\"].obs[index].squeeze(0)[idx]\n",
    "                        else:\n",
    "                            temp_input[obs_step.name] = terminal_info[\"terminal_steps\"].obs[index].squeeze(0).squeeze(0)\n",
    "                        \n",
    "                    else:\n",
    "                        temp_input = addDirectionLayer(temp_input, terminal_info[\"terminal_steps\"].obs[index])\n",
    "                        print(f'other observation: {terminal_info[\"terminal_steps\"].obs[index].shape}')\n",
    "            \n",
    "                agents_obs[terminal_info[\"agent_name\"]] = temp_input\n",
    "    \n",
    "                print(agents_obs[terminal_info[\"agent_name\"]].keys())\n",
    "                print(\"cannot use this due to my lack of skills...\")\n",
    "                next_values = []\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                agents_obs = dict()\n",
    "                agents_obs_in_array = []\n",
    "                for index, agent_name in enumerate(agent_names):\n",
    "                    spec = env.behavior_specs[agent_name]\n",
    "            \n",
    "                    decision_steps, terminal_steps = env.get_steps(agent_name)\n",
    "                    \n",
    "                    temp_input = dict()\n",
    "                        \n",
    "                    for index, obs_step in enumerate(spec.observation_specs):\n",
    "                        \n",
    "                        if len(obs_step.shape) == 3:\n",
    "                            # print(f\"obs_name: {obs_step.name}, shape: {decision_steps.obs[index].shape}\")\n",
    "                            if obs_step.name == \"CameraSensor\":\n",
    "                                for idx in range(len(decision_steps.obs[index].squeeze(0) )):\n",
    "                                    temp_input[f\"{obs_step.name}_{idx + 1}\"] = decision_steps.obs[index].squeeze(0)[idx]\n",
    "                            else:\n",
    "                                temp_input[obs_step.name] = decision_steps.obs[index].squeeze(0).squeeze(0)\n",
    "            \n",
    "                            \n",
    "                        else:\n",
    "                            temp_input = addDirectionLayer(temp_input, decision_steps.obs[index])\n",
    "                            # print(f\"other observation: {decision_steps.obs[index].shape}\")\n",
    "                \n",
    "                    agents_obs[agent_name] = temp_input\n",
    "                    \n",
    "                agents_obs[agent1]= addOtherAgentLayers(agents_obs, agent1, agent2)\n",
    "                agents_obs[agent2] = addOtherAgentLayers(agents_obs, agent2, agent1)\n",
    "            \n",
    "                #input dictionary -> sorted array (as sorted_obs_order)\n",
    "                for agent_name in agent_names:\n",
    "                    agent_obs_in_array = []\n",
    "                    for sorted_layer in sorted_obs_order:\n",
    "                        agent_obs_in_array.append(agents_obs[agent_name][sorted_layer])\n",
    "                    agents_obs_in_array.append(agent_obs_in_array)\n",
    "                \n",
    "                agents_obs_in_array = np.array(agents_obs_in_array, dtype=np.float32)\n",
    "                \n",
    "                agents_obs_in_array = torch.from_numpy(agents_obs_in_array).to(device)\n",
    "    \n",
    "                next_values = critic_model(agents_obs_in_array)\n",
    "                \n",
    "            returns_all = compute_GAE_dict(next_values, values_all, rewards_all, gamma_param, lambd_param)\n",
    "            \n",
    "            assert len(values_all[\"agent1\"]) == len(returns_all[\"agent1\"]) \n",
    "            \n",
    "            advantages_all = compute_Advantage_dict(values_all, returns_all)\n",
    "            \n",
    "            states_all[\"agent1\"], states_all[\"agent2\"] = states_agent1, states_agent2\n",
    "    \n",
    "            #convert list into tensor for ppo\n",
    "            states_all = convert_list_into_tensor_dict(states_all)\n",
    "            log_probs_all = convert_list_into_tensor_dict(log_probs_all) \n",
    "            entropy_all = convert_list_into_tensor_dict(entropy_all)\n",
    "            values_all = concat_tensor_dict(values_all)\n",
    "            returns_all = convert_list_into_tensor_dict(returns_all)\n",
    "            advantages_all = concat_tensor_dict(advantages_all)\n",
    "            \n",
    "            agent1_str = \"agent1\"\n",
    "            agent2_str = \"agent2\"\n",
    "\n",
    "            total_rewards_epochs.append(calc_total_reward(rewards_all))\n",
    "            # print(f\"epoch {num_epoch}: total_rewards = {total_rewards_epochs[-1]}\")\n",
    "            \n",
    "            num_agents = len(agent_names)\n",
    "    \n",
    "            dict_keys = [\"agent1\", \"agent2\"]\n",
    "            mappo_update(ppo_epoch, ppo_batch_size, dict_keys, states_all, log_probs_all, entropy_all, advantages_all, entropy_coef_param)    \n",
    "            critic_update(ppo_epoch, ppo_batch_size, mini_batch_size, dict_keys, states_all, values_all, returns_all)\n",
    "\n",
    "        total_rewards_all.append(total_rewards_epochs)\n",
    "        \n",
    "        onnx_file_path = f\"agent_model_param_{str(num_epochs)}_epochs.onnx\"\n",
    "        torch.onnx.export(\n",
    "            agent_model,\n",
    "            states_all[\"agent1\"][0].unsqueeze(0),\n",
    "            onnx_file_path,\n",
    "            export_param=True,\n",
    "            opset_version=11,\n",
    "            do_constant_folding=True,\n",
    "            input_names=[\"input\"],\n",
    "            output_names=[\"output\"],\n",
    "        )\n",
    "            \n",
    "    # for epoch, rewards in enumerate(total_rewards_all):\n",
    "    #     print(f\"epoch: {epoch}, rewards: {rewards}\")\n",
    "    \n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d23e25b-86a8-462a-b87d-50c46b401d02",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6])\n"
     ]
    }
   ],
   "source": [
    "a = torch.from_numpy(np.random.random([2,6]))\n",
    "print(a[0].unsqueeze(0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7d99df3c-5f95-471f-a76e-5cd7de2c3b7d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UnityMemory] Configuration Parameters - Can be set up in boot.config\n",
      "    \"memorysetup-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-main-allocator-block-size=16777216\"\n",
      "    \"memorysetup-gfx-thread-allocator-block-size=16777216\"\n",
      "    \"memorysetup-cache-allocator-block-size=4194304\"\n",
      "    \"memorysetup-typetree-allocator-block-size=2097152\"\n",
      "    \"memorysetup-profiler-bucket-allocator-granularity=16\"\n",
      "    \"memorysetup-profiler-bucket-allocator-bucket-count=8\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-size=4194304\"\n",
      "    \"memorysetup-profiler-bucket-allocator-block-count=1\"\n",
      "    \"memorysetup-profiler-allocator-block-size=16777216\"\n",
      "    \"memorysetup-profiler-editor-allocator-block-size=1048576\"\n",
      "    \"memorysetup-temp-allocator-size-main=4194304\"\n",
      "    \"memorysetup-job-temp-allocator-block-size=2097152\"\n",
      "    \"memorysetup-job-temp-allocator-block-size-background=1048576\"\n",
      "    \"memorysetup-job-temp-allocator-reduction-small-platforms=262144\"\n",
      "    \"memorysetup-allocator-temp-initial-block-size-main=262144\"\n",
      "    \"memorysetup-allocator-temp-initial-block-size-worker=262144\"\n",
      "    \"memorysetup-temp-allocator-size-background-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-job-worker=262144\"\n",
      "    \"memorysetup-temp-allocator-size-preload-manager=262144\"\n",
      "    \"memorysetup-temp-allocator-size-nav-mesh-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-audio-worker=65536\"\n",
      "    \"memorysetup-temp-allocator-size-cloud-worker=32768\"\n",
      "    \"memorysetup-temp-allocator-size-gfx=262144\"\n",
      "Agents: ['ChefAgent?team=0', 'ChefAgent2?team=0']\n",
      "<class 'mlagents_envs.base_env.BehaviorMapping'>\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "796aed3b-4561-466a-aa4d-b0ad36b1bac4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[6.0, 6.0]]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_rewards_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a6deab2-a0be-477b-b36b-e147a05102f1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(total_rewards_all))\n",
    "print(len(total_rewards_all[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f6b3eb1a-50ba-45b8-bcb0-1707baa9cccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4cc6ebe3-1441-4322-9a6a-976f148b099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save_graph(total_rewards_all):\n",
    "    for total_reward in total_rewards_all:\n",
    "        flat_data = total_reward  # Now it's (300, 2)\n",
    "        \n",
    "        # Create X-axis (indices 0 to 299)\n",
    "        x = list(range(len(total_reward)))\n",
    "        \n",
    "        # Extract the two Y-axis series\n",
    "        y1 = [pair[0] for pair in flat_data]  # First value in each pair\n",
    "        y2 = [pair[1] for pair in flat_data]  # Second value in each pair\n",
    "        \n",
    "        # Plot the data\n",
    "        plt.plot(x, y1, label=\"total rewards (agent1)\", color='blue')\n",
    "        plt.plot(x, y2, label=\"total rewards (agent2)\", color='orange')\n",
    "        \n",
    "        # Customize the graph\n",
    "        plt.title(\"Total rewards of each agent\")\n",
    "        plt.xlabel(\"epoch\")\n",
    "        plt.ylabel(\"total rewards\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.savefig(f\"graph_output_{len(total_reward)}_epochs.png\", dpi=800, format='png')  # Save as PNG with 300 DPI\n",
    "        \n",
    "        \n",
    "        # Display the graph\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9cc8bcc4-0079-41f9-a2f8-2a596fe07d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_and_save_graph(total_rewards_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe5498e-fc13-49ec-b3b0-29f4cdb85c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
